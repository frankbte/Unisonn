{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2154f8d-66aa-40c0-ab0a-e3c80dc8e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from scipy import ndimage\n",
    "import requests\n",
    "import gzip\n",
    "import os\n",
    "import hashlib\n",
    "\n",
    "plt.ioff();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0909eb-3478-4b0b-b943-74900de62e71",
   "metadata": {},
   "source": [
    "# Características no lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf05acd-9c4c-42da-9f49-7652302ad113",
   "metadata": {},
   "source": [
    "Incluso utilizando una maquinaria lineal, podemos obtener predictores no lineales a partir del extractor de características."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060d7f07-9bdf-425f-9a53-939796eb7f26",
   "metadata": {},
   "source": [
    "## Regresión\n",
    "\n",
    "Recordemos que en los problemas de regresión, a partir de datos de entrenamiento, un algoritmo de aprendizaje produce un predictor que asocia nuevas entradas a nuevas salidas.\n",
    "\n",
    "La primer decisión de diseño corresponde a responder ¿cuáles son los posibles predictores que puede considerar el algoritmo de aprendizaje? es decir, debemos determinar nuestra **clase de hipótesis**.\n",
    "\n",
    "Para predictores lineales, la clase de hipótesis es el conjunto de predictores que asocian algúna entrada $x$ al producto punto entre un vector de pesos $\\mathbf{w}$ y un vector de características $\\phi(x)$.\n",
    "\n",
    "Si definimos nuestro extractor de características como $\\phi(x)=[1, x]$, entonces podemos construir un predictor lineal a partir de pesos $\\mathbf{w} = [w_1, w_2]$ donde $w_2$ es la pendiente y $w_1$ la ordenada al origen.\n",
    "\n",
    "**¿Qué pasa si tenemos datos más complejos?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3eb5c-3cd5-4a87-9745-3a4a61bd68f0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "np.random.seed(42)\n",
    "xs = np.random.rand(20) * 5\n",
    "ys = -0.2*(xs ** 2) + xs + 2 + (np.random.rand(20)-0.5)\n",
    "ax.scatter(xs, ys, c = \"green\")\n",
    "ax.set_xlim((0,5))\n",
    "ax.set_ylim((0,4.1))\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"$y$\")\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "display(fig.canvas);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e6ccdf-f0ac-4cb2-817d-ceb4beff467b",
   "metadata": {},
   "source": [
    "**¿Cómo podemos ajustar un predictor no lineal?**\n",
    "\n",
    "Una ruta es recurrir inmediatamente a maquinarias más expresivas como redes neuronales.\n",
    "\n",
    "Pero veamos primero que tanto jugo podemos sacarle a la maquinaria lineal de los predictores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9bca67-3d4c-4ebf-990d-dd35fbb519f8",
   "metadata": {},
   "source": [
    "### Predictores cuadráticos\n",
    "\n",
    "La clave es observar que el extractor de características $\\phi$ puede ser arbitrario.\n",
    "\n",
    "Podemos definirlo para incluir un término cuadrático.\n",
    "\n",
    "$$\\phi(x) = [1, x, x^2]$$\n",
    "\n",
    "Incorporando los pesos apropiadamente, podemos definir un predictor no lineal (específicamente, un predictor **cuadrático**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43c9c9a-ea4e-43d5-9357-3570af49f904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_squared(x):\n",
    "    return [1, x, x ** 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d69dfc-7e07-4395-811a-951b5df74005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, x):\n",
    "    return np.array(w).dot(features_squared(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927f9ce7-4373-4dbc-9374-cc4089102d30",
   "metadata": {},
   "source": [
    "Consideremos como ejemplos tres predictores:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\mathbf{w}_1 &= [2, 1, -0.2] \\\\\n",
    "\\mathbf{w}_2 &= [4, -1, 0.1] \\\\\n",
    "\\mathbf{w}_3 &= [1, 1, 0]\n",
    "\\end{aligned}$$\n",
    "\n",
    "La clase de hipótesis es entonces:\n",
    "\n",
    "$$\\mathcal{F} = \\left\\{ f_\\mathbf{w}(x) = \\mathbf{w}\\cdot\\phi(x) \\mid \\mathbf{w}\\in\\mathbb{R}^3 \\right\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322bd04-c81a-4eaa-a36f-3a3209f0556c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "np.random.seed(42)\n",
    "xs = np.random.rand(20) * 5\n",
    "ys = -0.2*(xs ** 2) + xs + 2 + (np.random.rand(20)-0.5)\n",
    "ax.scatter(xs, ys, c = \"green\")\n",
    "\n",
    "w1 = [2, 1, -0.2]\n",
    "w2 = [4, -1, 0.1]\n",
    "w3 = [1, 1, 0]\n",
    "\n",
    "xs = np.linspace(0, 5, 100)\n",
    "ys1 = [predict(w1, x) for x in xs]\n",
    "ys2 = [predict(w2, x) for x in xs]\n",
    "ys3 = [predict(w3, x) for x in xs]\n",
    "\n",
    "ax.plot(xs, ys1, c = \"red\", label = \"$\\\\mathbf{w}_1$\")\n",
    "ax.plot(xs, ys2, c = \"purple\", label = \"$\\\\mathbf{w}_2$\")\n",
    "ax.plot(xs, ys3, c = \"orange\", label = \"$\\\\mathbf{w}_3$\")\n",
    "\n",
    "ax.set_xlim((0,5))\n",
    "ax.set_ylim((0,4.1))\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"$y$\")\n",
    "ax.legend()\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "display(fig.canvas);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcc46bb-be25-4d44-bcbf-f84b165ac1f0",
   "metadata": {},
   "source": [
    "Si un vector tiene en su última componente el valor de $0$, entonces el predictor asociado es lineal. La clase de hipótesis que consideramos en este ejemplo es un superconjunto de la clase de hipótesis de predictores lineales.\n",
    "\n",
    "**¿Qué problema puede haber si consideramos entradas con más dimensiones?**\n",
    "\n",
    "En lugar de $x\\in\\mathbb{R}$ piensa en $x\\in\\mathbb{R}^d$ para $d$ grande."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d42fe34-999c-496e-8d9e-95ef150e40b5",
   "metadata": {},
   "source": [
    "### Predictores por partes constantes\n",
    "\n",
    "Los predictores cuadráticos siguen siendo algo restrictivos, solo pueden subir y luego bajar suavemente (o viceversa).\n",
    "\n",
    "Otro tipo de extractor de características divide el espacio de entrada en regiones y permite que el valor predecido de cada región varíe independientemente, produciendo predictores por partes constantes.\n",
    "\n",
    "$$\\phi(x) = [\\mathbf{1}[0<x\\leq1], \\mathbf{1}[1<x\\leq2], \\mathbf{1}[2<x\\leq3], \\mathbf{1}[3<x\\leq4], \\mathbf{1}[4<x\\leq5]]$$\n",
    "\n",
    "Cada componente del vector de características corresponde a una región (por ejemplo $[0,1)$) y es $1$ si $x$ cae dentro de la región y es $0$ en otro caso.\n",
    "\n",
    "Suponiendo que las regiones son disjuntas, el peso asociado a cada componente/región es precisamente el valor predecido.\n",
    "\n",
    "Conforme las regiones se consideran más pequeñas, habremos de considerar más características, y la expresividad de la clase de hipótesis crece linealmente. En el límite, puedes esencialmente capturar cualquier predictor que desees.\n",
    "\n",
    "Considera la clase de hipótesis:\n",
    "\n",
    "$$\\mathcal{F} = \\left\\{ f_\\mathbf{w}(x) = \\mathbf{w}\\cdot\\phi(x) \\mid \\mathbf{w}\\in\\mathbb{R}^5 \\right\\}$$\n",
    "\n",
    "Y los predictores:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\mathbf{w}_1 &= [1, 2, 4, 4, 3] \\\\\n",
    "\\mathbf{w}_2 &= [4, 3, 3, 2, 1.5]\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219e79a1-d35f-495b-8eab-a2af66165eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_piecewise(x):\n",
    "    return [\n",
    "        1 if 0 < x <= 1 else 0,\n",
    "        1 if 1 < x <= 2 else 0,\n",
    "        1 if 2 < x <= 3 else 0,\n",
    "        1 if 3 < x <= 4 else 0,\n",
    "        1 if 4 < x <= 5 else 0,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e240e24-ac29-4c3a-84aa-4bf14c1a8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, x):\n",
    "    return np.array(w).dot(features_piecewise(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169c7a3a-c99e-404f-b323-f0412137abf9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "w1 = [1, 2, 4, 4, 2]\n",
    "w2 = [4, 3, 3, 2, 1.5]\n",
    "\n",
    "xs = np.linspace(0, 5, 500)\n",
    "ys1 = [predict(w1, x) for x in xs]\n",
    "ys2 = [predict(w2, x) for x in xs]\n",
    "\n",
    "ax.plot(xs, ys1, c = \"red\", label = \"$\\\\mathbf{w}_1$\")\n",
    "ax.plot(xs, ys2, c = \"purple\", label = \"$\\\\mathbf{w}_2$\")\n",
    "\n",
    "ax.set_xlim((0,5))\n",
    "ax.set_ylim((0,4.1))\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"$y$\")\n",
    "ax.legend()\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "display(fig.canvas);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974548f3-7598-46d6-a786-73bc288b64a6",
   "metadata": {},
   "source": [
    "**¿Qué pasa si $x$ no es un escalar si no un vector $d$-dimensional?**\n",
    "\n",
    "Considera que cada componente deberá asociarse a una de $B$ regiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06099923-f34f-4e8b-977c-7f75d38b089c",
   "metadata": {},
   "source": [
    "### Predictores con estructura periódica\n",
    "\n",
    "> Quítale lo aburrido, ponle lo divertido\n",
    "\n",
    "**¡Incorpora las características que quieras!**\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\phi(x) &= [1, x, x^2, \\cos(3x)] \\\\\n",
    "\\mathbf{w}_1 &= [1, 1, -0.1, 1] \\\\\n",
    "\\mathbf{w}_2 &= [3, -1, 0.1, 0.5]\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540fe3ad-56cb-458e-b25c-7c0fef99afdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_periodic(x):\n",
    "    return [1, x, x ** 2, np.cos(3*x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1bf415-753a-4c9f-92ba-ebfbaae71326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, x):\n",
    "    return np.array(w).dot(features_periodic(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b5209-6043-4f68-a75d-1902021b3c8b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "w1 = [1, 1, -0.1, 1]\n",
    "w2 = [3, -1, 0.1, 0.5]\n",
    "\n",
    "xs = np.linspace(0, 5, 100)\n",
    "ys1 = [predict(w1, x) for x in xs]\n",
    "ys2 = [predict(w2, x) for x in xs]\n",
    "\n",
    "ax.plot(xs, ys1, c = \"red\", label = \"$\\\\mathbf{w}_1$\")\n",
    "ax.plot(xs, ys2, c = \"purple\", label = \"$\\\\mathbf{w}_2$\")\n",
    "\n",
    "ax.set_xlim((0,5))\n",
    "ax.set_ylim((0,4.1))\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"$y$\")\n",
    "ax.legend()\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "display(fig.canvas);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96903ddc-0f3b-48a8-bf1c-7c09ea6e674c",
   "metadata": {},
   "source": [
    "¿Cómo podemos obtener predictores no lineales si seguimos utilizando la maquinaria de los predictores lineales?\n",
    "\n",
    "Estamos usando el término *lineal* de manera ambigüa.\n",
    "\n",
    "- La respuesta $\\mathbf{w}\\cdot\\phi(x)$ es lineal con respecto a $\\mathbf{w}$\n",
    "- La respuesta $\\mathbf{w}\\cdot\\phi(x)$ es lineal con respecto a $\\phi(x)$\n",
    "- La respuesta $\\mathbf{w}\\cdot\\phi(x)$ **no** es lineal con respecto a $x$\n",
    "\n",
    "Es posible que esta no linealidad con respecto a $x$ ni siquiera tenga sentido ¡$x$ no necesariamente es un vector! pudiera ser una imágen, un archivo PDF, una novela representada como cadena de caracteres...\n",
    "\n",
    "Desde la perspectiva del algoritmo de aprendizaje, el cuál observa a $\\phi(x)$ pero no a $x$), la linealidad nos permite optimizar los pesos eficientemente.\n",
    "\n",
    "Si la respuesta es lineal con respecto a $\\mathbf{w}$ y la función de pérdida es convexa (lo cuál es el caso para la pérdida cuadrática, de articulación y la logística, pero no es el caso para la pérdida cero-uno), entonces minimizar la pérdida de entrenamiento es un problema de **optimización convexa** y el descenso de gradiente (con un tamaño de paso apropiado) está destinado a converger al mínimo global."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6fa9c3-f8fc-4011-9bb3-dd0c95a27c12",
   "metadata": {},
   "source": [
    "## Clasificación\n",
    "\n",
    "En problemas de clasificación también puedes definir características arbitrarias para producir clasificadores no lineales.\n",
    "\n",
    "Recuerda que en la clasificación binaria el clasificador regresa el signo de la respuesta.\n",
    "\n",
    "El clasificador puede entonces ser representado por su frontera de decisión, la cuál divide el espacio de entrada en dos regiones: los puntos con respuesta positiva y los puntos con respuesta negativa.\n",
    "\n",
    "### Clasificadores cuadráticos\n",
    "\n",
    "Consideremos como ejemplos un clasificador con frontera de decisión no lineal, partiendo el espacio de entrada con un círculo: los puntos dentro del círculo son clasificados con $+1$ y los puntos fuera del círculo son clasificados con $-1$.\n",
    "\n",
    "$$\\begin{align}\n",
    "\\phi(x) &= [x_1, x_2, x_1^2 + x_2^2] \\\\\n",
    "f_\\mathbf{w}(x) &= \\text{sign}(\\mathbf{w}\\cdot\\phi(x)) \\\\\n",
    "\\mathbf{w}_1 &= [2, 2, -1] \\\\\n",
    "f_{\\mathbf{w}_1}(x) &= \\text{sign}([2, 2, -1]\\cdot[x_1, x_2, x_1^2 + x_2^2]) \\\\\n",
    "&= \\text{sign}(2x_1 + 2x_2 - x_1^2 - x_2^2) \\\\\n",
    "&= \\begin{cases}\n",
    "+1 &\\text{si } 2x_1 + 2x_2 - x_1^2 - x_2^2 \\geq 0 \\\\\n",
    "-1 &\\text{en otro caso}\n",
    "\\end{cases} \\\\\n",
    "&= \\begin{cases}\n",
    "+1 &\\text{si } x_1^2 + x_2^2 - 2x_1 - 2x_2 + 2 \\leq 2 \\\\\n",
    "-1 &\\text{en otro caso}\n",
    "\\end{cases} \\\\\n",
    "&= \\begin{cases}\n",
    "+1 &\\text{si } x_1^2 - 2x_1 + 1 + x_2^2 - 2x_2 + 1 \\leq 2 \\\\\n",
    "-1 &\\text{en otro caso}\n",
    "\\end{cases} \\\\\n",
    "&= \\begin{cases}\n",
    "+1 &\\text{si } (x_1 - 1)^2 + (x_2 - 1)^2 \\leq 2 \\\\\n",
    "-1 &\\text{en otro caso}\n",
    "\\end{cases}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8092b6-5e0d-4115-b12b-38fbd20886c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_circle(x):\n",
    "    return [x[0], x[1], x[0]**2 - x[1]**2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7753e93-73af-4c40-b2de-132b72365b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, x):\n",
    "    return np.sign(np.array(w).dot(features_circle(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b931e8b-789e-41c1-a824-34ab93994798",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "w = [2, 2, -1]\n",
    "\n",
    "xs = list(np.linspace(-3, 3, 100))\n",
    "x1s, x2s = [], []\n",
    "for x1 in xs:\n",
    "    for x2 in xs:\n",
    "        x1s.append(x1)\n",
    "        x2s.append(x2)\n",
    "\n",
    "x1sPos, x2sPos = [], []\n",
    "x1sNeg, x2sNeg = [], []\n",
    "for x1, x2 in zip(x1s, x2s):\n",
    "    if predict(w, [x1, x2]) >= 0:\n",
    "        x1sPos.append(x1)\n",
    "        x2sPos.append(x2)\n",
    "    else:\n",
    "        x1sNeg.append(x1)\n",
    "        x2sNeg.append(x2)\n",
    "\n",
    "ax.scatter(x1sPos, x2sPos, c = \"purple\", marker = \".\", label = \"$+1$\")\n",
    "ax.scatter(x1sNeg, x2sNeg, c = \"orange\", marker = \".\", label = \"$-1$\")\n",
    "\n",
    "ax.set_xlim((-3, 3))\n",
    "ax.set_ylim((-3, 3))\n",
    "ax.set_xlabel(\"$x_1$\")\n",
    "ax.set_ylabel(\"$x_2$\")\n",
    "ax.legend()\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "display(fig.canvas);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbaa812-6fa0-4491-885c-18998b408070",
   "metadata": {},
   "source": [
    "# Plantillas de características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ea1843-9159-49b7-8fb7-b8022fdf3550",
   "metadata": {},
   "source": [
    "Ahora discutiremos cómo podemos usar plantillas de características para construir características de manera flexible.\n",
    "\n",
    "Recuerda que la clase de hipótesis $\\mathcal{F}$ es el conjunto de predictores considerados por nuestro algoritmo de aprendizaje.  En el caso de los predictores lineales, $\\mathcal{F}$ está dado por alguna función de $\\mathbf{w}\\cdot\\phi(x)$ para todas las $\\mathbf{w}$.\n",
    "\n",
    "El aprendizaje es el proceso de elegir un predictor particular $f_\\mathbf{w}$ de $\\mathcal{F}$ dado un conjunto de entrenamiento.\n",
    "\n",
    "La pregunta que nos concierne ahora es ¿Cómo elegimos $\\mathcal{F}$? Ya discutimos predictores lineales, cuadráticos, etc. ¿Qué hace sentido para la aplicación que trabajamos?\n",
    "\n",
    "Si la clase de hipótesis no contiene buenos predictores, no importa que tan bueno sea nuestro aprendizaje.  La pregunta es si la extracción de características es suficientemente buena para **expresar** buenos predictores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55455fd-fb40-4f6b-b1ed-02307a8c3e13",
   "metadata": {},
   "source": [
    "## Validación de correos electrónicos\n",
    "\n",
    "Considera la tarea de predecir si una cadena es una dirección de correo electrónico válida o no.\n",
    "\n",
    "Supongamos que el clasificador $f_\\mathbf{w}$ es lineal, dado por algún extractor de características $\\phi$.\n",
    "\n",
    "Extraer características apropiadas es todo un arte y requiere intuición sobre el problema en cuestión y también sobre las capacidades de los algoritmos de aprendizaje máquina.\n",
    "\n",
    "La idea clave es que las características deben representar propiedades de $x$ que **puedan ser** relevantes para predecir $y$.\n",
    "\n",
    "$$x = \\mathtt{abc@gmail.com}$$\n",
    "$$\\Downarrow$$\n",
    "$$\\phi$$\n",
    "$$\\Downarrow$$\n",
    "| característica | valor |\n",
    "|----------------|-------|\n",
    "| `length>10`    | 1     |\n",
    "| `fracOfAlpha`  | 0.85  |\n",
    "| `contains_@`   | 1     |\n",
    "| `endsWith_com` | 1     |\n",
    "| `endsWith_org` | 0     |\n",
    "\n",
    "El extractor debe producir un conjunto de pares que consisten del nombre de la característica y su valor. Podemos extraer información sobre la longitud, la proporción de caracteres alfanuméricos, o si contiene algunas subcadenas.\n",
    "\n",
    "No te preocupes si agregas características que resultan ser irrelevantes, ya que el algoritmo de aprendizaje puede en principio decidir ignorar esa característica, aunque quizá requiera procesar más datos para ello."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b099b85e-115c-4f3b-b6c2-15d017e93f7f",
   "metadata": {},
   "source": [
    "Un vector de características formalmente es solo una lista de números, pero hemos aumentado cada característica en el vector con un nombre. El vector de pesos también es solo una lista de números, también  lo aumentaremos con un nombre para cada peso.\n",
    "\n",
    "$$\\text{Vector de pesos } \\mathbf{w}\\in\\mathbb{R}^d$$\n",
    "|                |       |\n",
    "|----------------|-------|\n",
    "| `length>10`    | -1.2  |\n",
    "| `fracOfAlpha`  | 0.6   |\n",
    "| `contains_@`   | 3     |\n",
    "| `endsWith_com` | 2.2   |\n",
    "| `endsWith_org` | 1.4   |\n",
    "\n",
    "$$\\text{Vector de características } \\phi(x)\\in\\mathbb{R}^d$$\n",
    "|                |       |\n",
    "|----------------|-------|\n",
    "| `length>10`    | 1     |\n",
    "| `fracOfAlpha`  | 0.85  |\n",
    "| `contains_@`   | 1     |\n",
    "| `endsWith_com` | 1     |\n",
    "| `endsWith_org` | 0     |\n",
    "\n",
    "Recuerda que la respuesta es simplemente el producto punto entre el vector de pesos y el vector de características. En otras palabras, la respuesta agrega la contribución de cada característica, ponderada apropiadamente.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\mathbf{w}\\cdot\\phi(x) &= \\sum_{j=1}^d w_j\\phi(x)_j \\\\\n",
    "&= -1.2(1) + 0.6(0.85) + 3(1) + 2.2(1) + 1.4(0) \\\\\n",
    "&= 4.510\n",
    "\\end{aligned}$$\n",
    "\n",
    "Cada peso $w_j$ determina cómo el valor de característica correspondiente $\\phi(x)_j$ contribuye a la predicción.  Si $w_j$ es positivo, entonces la presencia de una característica $j$ favorece una clasificación positiva (por ejemplo, que termine la dirección en `.com`). En cambio, si $w_j$ es negativa, entonces la presencia de una característica $j$ favorece una clasificación negativa (por ejemplo, que la longitud sea mayor a 10).  La magnitud de $w_j$ mide la fuerza o importancia de su contribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a2399f-5b9b-455d-a2f9-8e969eebe545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(x):\n",
    "    return {\n",
    "        \"length>10\": int(len(x) > 10),\n",
    "        \"fracOfAlpha\": len([c for c in x if c.isalpha()]) / len(x),\n",
    "        \"contains_@\": int(\"@\" in x),\n",
    "        \"endsWith_com\": int(len(x) >= 3 and x[-1:-4:-1][::-1] == \"com\"),\n",
    "        \"endsWith_org\": int(len(x) >= 3 and x[-1:-4:-1][::-1] == \"org\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf52cd3-13d9-4dcf-a11f-bb9ac0ceac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "features(\"abc@gmail.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad9677f-2aca-4603-bdde-73382c889edd",
   "metadata": {},
   "source": [
    "En el ejemplo anterior definimos ciertas características que creíamos que serían útiles para detectar direcciones de correo electrónico.  Sin embargo, es fácil omitir algunas características (como por ejemplo `endsWith_mx`), y también pueden haber otras características que permiten una buena predicción pero no son intuitivas.\n",
    "\n",
    "Necesitamos un principio organizacional, una manera sistemática de definir características..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc0716f-6169-4dcc-a4a9-945d79e24d3a",
   "metadata": {},
   "source": [
    "## Plantillas de características\n",
    "\n",
    "Una **plantilla de características** es un grupo de características que se calculas de manera similar.\n",
    "\n",
    "En lugar de definir características individuales como `endsWith_com`, podemos definir una plantilla que se expanda a todas las características que computen la coincidencia de los tres últimos caracteres de $x$.\n",
    "\n",
    "$$\\mathtt{abc@gmail.com}$$\n",
    "$$\\Downarrow$$\n",
    "$$\\text{los últimos tres caracteres son \\_\\_\\_}$$\n",
    "$$\\Downarrow$$\n",
    "|                |   |\n",
    "|----------------|---|\n",
    "| `endsWith_aaa` | 0 |\n",
    "| `endsWith_aab` | 0 |\n",
    "| `endsWith_aac` | 0 |\n",
    "| $\\dots$        |   |\n",
    "| `endsWith_com` | 1 |\n",
    "| $\\dots$        |   |\n",
    "| `endsWith_zzz` | 0 |\n",
    "\n",
    "No necesitamos conocer cuáles patrones particulares (como sufijos de tres caracteres) son útiles, solo que la **existencia** de algunos patrones pudieran ser útiles.\n",
    "\n",
    "Entonces es trabajo del algoritmo de aprendizaje discernir cuáles patrones son útiles asignando pesos apropiadamente.\n",
    "\n",
    "**¿Qué implementación de vector es más apropiada?** arreglos para características densas, diccionarios para características dispersas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b078fcd-f7e6-4b0e-a98b-9f53dd77c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def endsWithFeatures(x):\n",
    "    if len(x) < 3:\n",
    "        return {}\n",
    "    suffix = x[-1:-4:-1][::-1]\n",
    "    if not suffix.isalpha():\n",
    "        return {}\n",
    "    return {\n",
    "        \"endsWith_\" + suffix: 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e4e40-e824-4c8a-b411-a7dcdcf96543",
   "metadata": {},
   "outputs": [],
   "source": [
    "endsWithFeatures(\"abc@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622489b7-6b30-4e59-9e83-b2dfec228f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "endsWithFeatures(\"pickles69@420.gglol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cb5a6c-c4ef-4839-b3ab-a5fb59fa32e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(x):\n",
    "    return {\n",
    "        \"length>10\": int(len(x) > 10),\n",
    "        \"fracOfAlpha\": len([c for c in x if c.isalpha()]) / len(x),\n",
    "        \"contains_@\": int(\"@\" in x),\n",
    "    } | endsWithFeatures(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651798e1-4192-461e-998f-b7eb9f7a9d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "features(\"abc@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52803a2-539c-49d2-9a4e-03c7bae49364",
   "metadata": {},
   "outputs": [],
   "source": [
    "features(\"eay2@eacuna.org\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d624fd6c-cda7-484a-9a76-140e74ce25cd",
   "metadata": {},
   "source": [
    "# Transformando imágenes\n",
    "\n",
    "Juguemos un poco con los datos de MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7021dc5e-204f-4865-9862-c8daf6969787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(url):\n",
    "    hash = hashlib.md5(url.encode(\"utf-8\")).hexdigest()\n",
    "    path = os.path.join(\".\", hash)\n",
    "    if os.path.isfile(path):\n",
    "        with open(path, \"rb\") as f:\n",
    "            data = f.read()\n",
    "    else:\n",
    "        with open(path, \"wb\") as f:\n",
    "            data = requests.get(url).content\n",
    "            f.write(data)\n",
    "    return np.frombuffer(\n",
    "        gzip.decompress(data),\n",
    "        dtype=np.uint8,\n",
    "    ).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad481f7-29e2-480f-a57e-840e7414f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = fetch(\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\")\n",
    "label_data = fetch(\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef35a4-0361-4485-8602-20ed8acdbe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "[image_magic] = image_data[0:4][::-1].copy().view(np.uint32)\n",
    "[image_total] = image_data[4:8][::-1].copy().view(np.uint32)\n",
    "[image_rows, image_cols] = image_data[8:16][::-1].copy().view(np.uint32)\n",
    "images = image_data[16:].reshape((image_total, image_rows, image_cols))\n",
    "[label_magic] = label_data[0:4][::-1].copy().view(np.uint32)\n",
    "[label_total] = label_data[4:8][::-1].copy().view(np.uint32)\n",
    "labels = label_data[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d41742-86ab-498b-8be4-429dd92e9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(img, digit = None, label = None):\n",
    "    plt.close()\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "    ax.imshow(img, cmap=mpl.cm.gray_r)\n",
    "    if digit is not None:\n",
    "        ax.set_title(f\"La imagen contiene el dígito {digit}\")\n",
    "    elif label is not None:\n",
    "        ax.set_title(label)\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83253ab2-0ba2-4888-a865-040e8a7b71de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "show_example(images[n], labels[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7408179d-a7d3-49e2-b419-dab901608b98",
   "metadata": {},
   "source": [
    "Esta imagen parece un uno, pero hay muchas formas de escribir este simple numeral, usualmente como un palito, a veces rotado, a veces no, ¿qué tan rotado?\n",
    "\n",
    "Consideramos de ejemplo esta imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9d3cd0-094e-4f77-9205-28cba1af4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = images[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9909d3-1264-4747-ae26-a7f88203f2e6",
   "metadata": {},
   "source": [
    "## Rotación\n",
    "\n",
    "Cada pixel en la imágen original es movido a otro de acuerdo a la transformación\n",
    "\n",
    "$$T = \\begin{bmatrix}\n",
    "\\cos\\theta & -\\sin\\theta \\\\\n",
    "\\sin\\theta & \\cos\\theta\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c298ba2-29b1-47bf-86dc-f70f21560284",
   "metadata": {},
   "source": [
    "Pensamos en un pixel como una coordenada en el plano y un valor de intensidad luminosa. En particular consideramos a la coordenada como un vector en $\\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0ab8d7-8e7a-418b-815b-29b911edf93a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "hmin, hmax = 0, 30\n",
    "vmin, vmax = 0, 30\n",
    "\n",
    "x_init, x_min, x_max, x_step = 14, 0, 27, 1\n",
    "y_init, y_min, y_max, y_step = 12, 0, 27, 1\n",
    "a_init, a_min, a_max, a_step = 0, -2, 2, 0.01\n",
    "\n",
    "def rotVec(x, y, theta):\n",
    "    return [\n",
    "        np.cos(theta)*x - np.sin(theta)*y,\n",
    "        np.sin(theta)*x + np.cos(theta)*y,\n",
    "    ]\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot()\n",
    "pixel = ax.arrow(0, 0, x_init, y_init, head_width=0.75, color=\"black\")\n",
    "rot = rotVec(x_init, y_init, np.pi*a_init)\n",
    "pixelT = ax.arrow(0, 0, rot[0], rot[1], head_width=0.75, color=\"blue\")\n",
    "ax.imshow(image, cmap=mpl.cm.autumn, alpha=1)\n",
    "\n",
    "ax.set_xlim((hmin, hmax))\n",
    "ax.set_ylim((vmin, vmax))\n",
    "ax.invert_yaxis()\n",
    "\n",
    "def update_plot(x, y, a):\n",
    "    pixel.set_data(x = 0, y = 0, dx = x, dy = y)\n",
    "    rot = rotVec(x, y, np.pi*a)\n",
    "    pixelT.set_data(x = 0, y = 0, dx = rot[0], dy = rot[1])\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "widget = ipywidgets.interactive(\n",
    "    update_plot,\n",
    "    x = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"x\",\n",
    "        value=x_init,\n",
    "        min=x_min,\n",
    "        max=x_max,\n",
    "        step=x_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    y = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"y\",\n",
    "        value=y_init,\n",
    "        min=y_min,\n",
    "        max=y_max,\n",
    "        step=y_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    a = ipywidgets.FloatSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"angle (*pi)\",\n",
    "        value=a_init,\n",
    "        min=a_min,\n",
    "        max=a_max,\n",
    "        step=a_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "display(widget)\n",
    "display(fig.canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1dab28-64af-4c80-b305-cc0dc1f9abe3",
   "metadata": {},
   "source": [
    "Regresemos a la imagen del $1$ ladeado.\n",
    "\n",
    "Consideremos de ejemplo el pixel en $(14, 12)$, es decir, en el renglón $12$ y la columna $14$. El cuál en la imagen tiene valor de:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a05330-ce84-4c28-a7d9-1f4bff7f344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image[14, 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2c90d8-6311-48d6-ae62-1991481a16ea",
   "metadata": {},
   "source": [
    "Supongamos que queremos rotar esta imagen $12^\\circ$ en contra de las manecillas del reloj, es decir, $-12^\\circ$ o lo equivalente en radianes $-12\\pi/180 = -0.20943951023931953$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332abab7-4775-4a70-9236-68daf0495695",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = -12*np.pi/180"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428507b1-4807-42d4-af91-1d293fa62961",
   "metadata": {},
   "source": [
    "Podemos encontrar la ubicación del pixel en la imagen transformada con el producto entre la matriz de transformación y la posición original.\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "\\cos\\theta & -\\sin\\theta \\\\\n",
    "\\sin\\theta & \\cos\\theta\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "14 \\\\ 12\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "14\\cos\\theta - 12\\sin\\theta \\\\\n",
    "14\\sin\\theta + 12\\cos\\theta\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "14\\cos\\frac{-12\\pi}{180} - 12\\sin\\frac{-12\\pi}{180} \\\\\n",
    "14\\sin\\frac{-12\\pi}{180} + 12\\cos\\frac{-12\\pi}{180}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "16.1890067 \\\\\n",
    "8.82700754\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e30605-1593-4c88-aecf-291ae329a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "              [np.sin(theta), np.cos(theta)]])\n",
    "pos = np.array([[14],\n",
    "                [12]])\n",
    "np.dot(T, pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91fe10c-0223-4e42-a2de-40a253637332",
   "metadata": {},
   "source": [
    "Esta transformación nos puede llevar a posiciones no enteras, por lo que existe un único pixel en esta nueva posición, queda entre varios pixeles.  Vamos a tomar el piso de ambas coordenadas para concluir que la nueva posición de este pixel es $(16, 8)$, es decir, el renglón $8$, columna $16$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2fa035-253a-4aa7-a645-d6d8410d0765",
   "metadata": {},
   "source": [
    "Esta operación de rotación se realiza con respecto al origen $(0, 0)$, podemos generalizar la transformación para realizarla con respecto a cualquier otro punto al incorporar un desplazamiento (offset). Trasladamos todas las posiciones al punto de rotación, rotamos con la matriz de transformación y posteriormente volvemos a trasladar para obtener las posiciones finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a1f87e-b418-474e-8a7d-cf7f8ec76819",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "hmin, hmax = 0, 30\n",
    "vmin, vmax = 0, 30\n",
    "\n",
    "x_init, x_min, x_max, x_step = 14, 0, 27, 1\n",
    "y_init, y_min, y_max, y_step = 12, 0, 27, 1\n",
    "a_init, a_min, a_max, a_step = 0, -2, 2, 0.01\n",
    "cx_init, cx_min, cx_max, cx_step = 0, 0, 27, 1\n",
    "cy_init, cy_min, cy_max, cy_step = 0, 0, 27, 1\n",
    "\n",
    "def rotVec(x, y, theta):\n",
    "    return [\n",
    "        np.cos(theta)*x - np.sin(theta)*y,\n",
    "        np.sin(theta)*x + np.cos(theta)*y,\n",
    "    ]\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot()\n",
    "pixel = ax.arrow(0, 0, x_init, y_init, head_width=0.75, color=\"black\")\n",
    "rot = rotVec(x_init, y_init, np.pi*a_init)\n",
    "pixelT = ax.arrow(0, 0, rot[0], rot[1], head_width=0.75, color=\"blue\")\n",
    "center = ax.plot([cx_init], [cy_init], color=\"blue\", marker = \"o\", linestyle = \"None\")\n",
    "ax.imshow(image, cmap=mpl.cm.autumn, alpha=1)\n",
    "\n",
    "ax.set_xlim((hmin, hmax))\n",
    "ax.set_ylim((vmin, vmax))\n",
    "ax.invert_yaxis()\n",
    "\n",
    "def update_plot(x, y, a, cx, cy):\n",
    "    pixel.set_data(x = 0, y = 0, dx = x, dy = y)\n",
    "    rot = rotVec(x - cx, y - cy, np.pi*a)\n",
    "    pixelT.set_data(x = 0, y = 0, dx = rot[0] + cx, dy = rot[1] + cy)\n",
    "    center[0].set_data([cx], [cy])\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "widget = ipywidgets.interactive(\n",
    "    update_plot,\n",
    "    x = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"x\",\n",
    "        value=x_init,\n",
    "        min=x_min,\n",
    "        max=x_max,\n",
    "        step=x_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    y = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"y\",\n",
    "        value=y_init,\n",
    "        min=y_min,\n",
    "        max=y_max,\n",
    "        step=y_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    a = ipywidgets.FloatSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"angle (*pi)\",\n",
    "        value=a_init,\n",
    "        min=a_min,\n",
    "        max=a_max,\n",
    "        step=a_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    cx = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"cx\",\n",
    "        value=cx_init,\n",
    "        min=cx_min,\n",
    "        max=cx_max,\n",
    "        step=cx_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    cy = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"cy\",\n",
    "        value=cy_init,\n",
    "        min=cy_min,\n",
    "        max=cy_max,\n",
    "        step=cy_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "display(widget)\n",
    "display(fig.canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6317ba-e4fd-4299-ab97-755779d9de0d",
   "metadata": {},
   "source": [
    "La siguiente implementación se encarga de rotar imagenes dado un ángulo y un desplazamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfabceec-59ee-43ee-b7e5-208b5b648673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(image, angle, offset = [0,0]):\n",
    "    T = np.array([[np.cos(angle), -np.sin(angle)],\n",
    "                  [np.sin(angle), np.cos(angle)]])\n",
    "    h, w = image.shape\n",
    "    off_x = offset[0]\n",
    "    off_y = offset[1]\n",
    "    imageT = np.zeros_like(image)\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            value = image[y, x]\n",
    "            pos = np.array([[x - off_x], [y - off_y]])\n",
    "            posT = np.dot(T, pos)\n",
    "            xT = off_x + int(posT[0][0])\n",
    "            yT = off_y + int(posT[1][0])\n",
    "            if (0 <= xT < w) and (0 <= yT < h):\n",
    "                imageT[yT,xT] = value\n",
    "    return imageT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc166790-1b61-41df-8751-fe5e29ee7ae4",
   "metadata": {},
   "source": [
    "Las siguientes tres imagenes corresponden respectivamente a:\n",
    "- La imagen sin rotación\n",
    "- La imagen rotada $-12^\\circ$ con respecto al origen\n",
    "- La imagen rotada $-12^\\circ$ con respecto al centro de la imagen $(14, 14)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f4f28f-5046-481a-871f-21308ae04f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(image, label=\"Imagen original\")\n",
    "show_example(rotate(image, theta, [0, 0]), label=\"Imagen rotada al origen\")\n",
    "show_example(rotate(image, theta, [14, 14]), label=\"Imagen rotada a (14,14)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4beae5-730a-4cb4-b3e9-92bc75128704",
   "metadata": {},
   "source": [
    "Observemos que aparecen algunos artefactos extraños, algunos pixeles sin tinta, algunas regiones mas delgadas o anchas a comparación de la original.  A este efecto se le conoce como *aliasing*, realizamos la transformación considerando que cada posición de los pixeles se encontraba en $\\mathbb{R}^2$, las transformamos linealmente en el continuo y luego discretizamos, perdiendo información y produciendo estos artefactos.\n",
    "\n",
    "Una antigua técnica para combatir los efectos del aliasing consiste en primero escalar hacia arriba la imagen original dos o cuatro veces, luego realizar la rotación y finalmente escalar hacia abajo promediando los valores en los pixeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3367ddc4-00a8-40ef-82b3-88bcdd0fff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale(image, factor = 2):\n",
    "    h, w = image.shape\n",
    "    imageT = np.zeros((factor * h, factor * w))\n",
    "    nh, nw = imageT.shape\n",
    "    for y in range(nh):\n",
    "        for x in range(nw):\n",
    "            value = image[y // factor, x // factor]\n",
    "            imageT[y, x] = value\n",
    "    return imageT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53921d37-ca68-44b2-a3d8-4d121b4e922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downscale(image, factor = 2):\n",
    "    h, w = image.shape\n",
    "    imageT = np.zeros((h // factor, w // factor))\n",
    "    nh, nw = imageT.shape\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            value = image[y, x] / factor\n",
    "            imageT[y // factor, x // factor] += value\n",
    "    return imageT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376e2a65-f6a6-45a7-adba-55b36b88e312",
   "metadata": {},
   "source": [
    "Las siguientes imagenes muestran respectivamente:\n",
    "- La imagen sin rotación\n",
    "- La imagen con rotación sin anti-aliasing\n",
    "- La imagen con rotación y anti-aliasing 2x\n",
    "- La imagen con rotación y anti-aliasing 4x\n",
    "- La imagen con rotación y anti-aliasing 8x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efcdda9-308b-4f11-8054-9fef2a5b8fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(image, label=\"Imagen original\")\n",
    "show_example(rotate(image, theta, [14, 14]), label=\"Imagen rotada a (14,14)\")\n",
    "show_example(rotate(upscale(image, 2), theta, [2*14, 2*14]), label=\"Imagen con anti-aliasing 2X rotada a (14,14)\")\n",
    "show_example(rotate(upscale(image, 4), theta, [4*14, 4*14]), label=\"Imagen con anti-aliasing 4X rotada a (14,14)\")\n",
    "show_example(rotate(upscale(image, 8), theta, [8*14, 8*14]), label=\"Imagen con anti-aliasing 8X rotada a (14,14)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db1672-bf01-45bc-8545-c7779592b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(image, label=\"Imagen original\")\n",
    "show_example(rotate(image, theta, [14, 14]), label=\"Imagen rotada\")\n",
    "show_example(downscale(rotate(upscale(image, 2), theta, [2*14, 2*14]), 2), label=\"Imagen rotada antialiasing 2X\")\n",
    "show_example(downscale(rotate(upscale(image, 4), theta, [4*14, 4*14]), 4), label=\"Imagen rotada antialiasing 4X\")\n",
    "show_example(downscale(rotate(upscale(image, 8), theta, [8*14, 8*14]), 8), label=\"Imagen rotada antialiasing 8X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc98b092-dc61-4165-8e85-1dfef995f54b",
   "metadata": {},
   "source": [
    "Podemos crear una abstracción sobre este proceso, a partir de una imagen, una matriz de transformación y un punto de origen para la transformación, realizar la operación utilizando esta técnica anti-aliasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbdd97c-e3ad-4c9a-ae15-1b6cac96273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image, T, offset = [0,0], antialiasing = 2):\n",
    "    image = upscale(image, antialiasing)\n",
    "    h, w = image.shape\n",
    "    off_x = offset[0] * antialiasing\n",
    "    off_y = offset[1] * antialiasing\n",
    "    imageT = np.zeros_like(image)\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            value = image[y, x]\n",
    "            pos = np.array([[x - off_x], [y - off_y]])\n",
    "            posT = np.dot(T, pos)\n",
    "            xT = int(off_x + int(posT[0][0]))\n",
    "            yT = int(off_y + int(posT[1][0]))\n",
    "            if (0 <= xT < w) and (0 <= yT < h):\n",
    "                imageT[yT,xT] = value\n",
    "    return downscale(imageT, antialiasing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dad061-d90a-4aae-8597-8da4fbe31967",
   "metadata": {},
   "source": [
    "La previa operación de rotación se obtiene de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b0f1fc-ef42-470d-a967-cc593da437dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotationT(angle):\n",
    "    return np.array([[np.cos(angle), -np.sin(angle)],\n",
    "                     [np.sin(angle), np.cos(angle)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be3c34b-b440-41a7-a8d1-90f71c394a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(image, label=\"Imagen original\")\n",
    "show_example(transform(\n",
    "    image,\n",
    "    rotationT(theta),\n",
    "    offset = [14, 14],\n",
    "), label=\"Imagen rotada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c002b82d-124d-4374-9986-a5796eb9f496",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "hmin, hmax = -1, 28\n",
    "vmin, vmax = -1, 28\n",
    "\n",
    "x_init, x_min, x_max, x_step = 14, 0, 27, 1\n",
    "y_init, y_min, y_max, y_step = 12, 0, 27, 1\n",
    "a_init, a_min, a_max, a_step = 0, -2, 2, 0.01\n",
    "cx_init, cx_min, cx_max, cx_step = 14, 0, 27, 1\n",
    "cy_init, cy_min, cy_max, cy_step = 14, 0, 27, 1\n",
    "\n",
    "def rotVec(x, y, theta):\n",
    "    return [\n",
    "        np.cos(theta)*x - np.sin(theta)*y,\n",
    "        np.sin(theta)*x + np.cos(theta)*y,\n",
    "    ]\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot()\n",
    "pixel = ax.arrow(0, 0, x_init, y_init, head_width=0.75, color=\"black\")\n",
    "rot = rotVec(x_init, y_init, np.pi*a_init)\n",
    "pixelT = ax.arrow(0, 0, rot[0], rot[1], head_width=0.75, color=\"blue\")\n",
    "center = ax.plot([cx_init], [cy_init], color=\"blue\", marker = \"o\", linestyle = \"None\")\n",
    "ax.imshow(image, cmap=mpl.cm.autumn, alpha=0.5)\n",
    "imgplot = ax.imshow(image, cmap=mpl.cm.autumn, alpha=0.5)\n",
    "\n",
    "ax.set_xlim((hmin, hmax))\n",
    "ax.set_ylim((vmin, vmax))\n",
    "ax.invert_yaxis()\n",
    "ax.set_title(\"Transformación con rotationT\")\n",
    "\n",
    "def update_plot(x, y, a, cx, cy):\n",
    "    pixel.set_data(x = 0, y = 0, dx = x, dy = y)\n",
    "    rot = rotVec(x - cx, y - cy, np.pi*a)\n",
    "    pixelT.set_data(x = 0, y = 0, dx = rot[0] + cx, dy = rot[1] + cy)\n",
    "    center[0].set_data([cx], [cy])\n",
    "    imgplot.set(data=transform(\n",
    "        image,\n",
    "        rotationT(np.pi*a),\n",
    "        offset = [cx, cy],\n",
    "    ), clip_on=False,)\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "widget = ipywidgets.interactive(\n",
    "    update_plot,\n",
    "    x = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"x\",\n",
    "        value=x_init,\n",
    "        min=x_min,\n",
    "        max=x_max,\n",
    "        step=x_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    y = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"y\",\n",
    "        value=y_init,\n",
    "        min=y_min,\n",
    "        max=y_max,\n",
    "        step=y_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    a = ipywidgets.FloatSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"angle (*pi)\",\n",
    "        value=a_init,\n",
    "        min=a_min,\n",
    "        max=a_max,\n",
    "        step=a_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    cx = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"cx\",\n",
    "        value=cx_init,\n",
    "        min=cx_min,\n",
    "        max=cx_max,\n",
    "        step=cx_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    cy = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"cy\",\n",
    "        value=cy_init,\n",
    "        min=cy_min,\n",
    "        max=cy_max,\n",
    "        step=cy_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "display(widget)\n",
    "display(fig.canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b2dcc6-1b4c-45fe-9d86-73cbb5805add",
   "metadata": {},
   "source": [
    "## Estiramiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d19710-97ff-4e6f-9161-4b0c7e3aa90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xstretchT(factor):\n",
    "    return np.array([[factor, 0],\n",
    "                     [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b534df-316f-478a-88f7-ef6cfceaa12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ystretchT(factor):\n",
    "    return np.array([[1, 0],\n",
    "                     [0, factor]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf429e2-adb0-4cee-ade0-5a4a76648227",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(image)\n",
    "show_example(transform(\n",
    "    image,\n",
    "    xstretchT(2),\n",
    "    offset = [14, 14],\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd26b3-fbe7-4b9b-8d4a-8d29293e0e9d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "hmin, hmax = -1, 28\n",
    "vmin, vmax = -1, 28\n",
    "\n",
    "x_init, x_min, x_max, x_step = 14, 0, 27, 1\n",
    "y_init, y_min, y_max, y_step = 12, 0, 27, 1\n",
    "k_init, k_min, k_max, k_step = 1, -3, 3, 0.01\n",
    "cx_init, cx_min, cx_max, cx_step = 14, 0, 27, 1\n",
    "cy_init, cy_min, cy_max, cy_step = 14, 0, 27, 1\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot()\n",
    "pixel = ax.arrow(0, 0, x_init, y_init, head_width=0.75, color=\"black\")\n",
    "pixelT = ax.arrow(0, 0, x_init, y_init, head_width=0.75, color=\"blue\")\n",
    "center = ax.plot([cx_init], [cy_init], color=\"blue\", marker = \"o\", linestyle = \"None\")\n",
    "ax.imshow(image, cmap=mpl.cm.autumn, alpha=0.5)\n",
    "imgplot = ax.imshow(image, cmap=mpl.cm.autumn, alpha=0.5)\n",
    "\n",
    "ax.set_xlim((hmin, hmax))\n",
    "ax.set_ylim((vmin, vmax))\n",
    "ax.invert_yaxis()\n",
    "ax.set_title(\"Transformación con xstretchT\")\n",
    "\n",
    "def update_plot(x, y, k, cx, cy):\n",
    "    pixel.set_data(x = 0, y = 0, dx = x, dy = y)\n",
    "    T = xstretchT(k)\n",
    "    pix = T.dot(np.array([x - cx, y - cy]))\n",
    "    pixelT.set_data(x = 0, y = 0, dx = pix[0] + cx, dy = pix[1] + cy)\n",
    "    center[0].set_data([cx], [cy])\n",
    "    imgplot.set(data=transform(\n",
    "        image,\n",
    "        T,\n",
    "        offset = [cx, cy],\n",
    "    ), clip_on=False,)\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "widget = ipywidgets.interactive(\n",
    "    update_plot,\n",
    "    x = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"x\",\n",
    "        value=x_init,\n",
    "        min=x_min,\n",
    "        max=x_max,\n",
    "        step=x_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    y = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"y\",\n",
    "        value=y_init,\n",
    "        min=y_min,\n",
    "        max=y_max,\n",
    "        step=y_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    k = ipywidgets.FloatSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"k\",\n",
    "        value=k_init,\n",
    "        min=k_min,\n",
    "        max=k_max,\n",
    "        step=k_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    cx = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"cx\",\n",
    "        value=cx_init,\n",
    "        min=cx_min,\n",
    "        max=cx_max,\n",
    "        step=cx_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    cy = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"cy\",\n",
    "        value=cy_init,\n",
    "        min=cy_min,\n",
    "        max=cy_max,\n",
    "        step=cy_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "display(widget)\n",
    "display(fig.canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cacedfb-26b8-42d6-8692-c829fdbb6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(image)\n",
    "show_example(transform(\n",
    "    image,\n",
    "    ystretchT(0.5),\n",
    "    offset = [14, 14],\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157bafb8-04ca-4653-8f93-716efa6b9fce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "hmin, hmax = -1, 28\n",
    "vmin, vmax = -1, 28\n",
    "\n",
    "x_init, x_min, x_max, x_step = 14, 0, 27, 1\n",
    "y_init, y_min, y_max, y_step = 12, 0, 27, 1\n",
    "k_init, k_min, k_max, k_step = 1, -3, 3, 0.01\n",
    "cx_init, cx_min, cx_max, cx_step = 14, 0, 27, 1\n",
    "cy_init, cy_min, cy_max, cy_step = 14, 0, 27, 1\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot()\n",
    "pixel = ax.arrow(0, 0, x_init, y_init, head_width=0.75, color=\"black\")\n",
    "pixelT = ax.arrow(0, 0, x_init, y_init, head_width=0.75, color=\"blue\")\n",
    "center = ax.plot([cx_init], [cy_init], color=\"blue\", marker = \"o\", linestyle = \"None\")\n",
    "ax.imshow(image, cmap=mpl.cm.autumn, alpha=0.5)\n",
    "imgplot = ax.imshow(image, cmap=mpl.cm.autumn, alpha=0.5)\n",
    "\n",
    "ax.set_xlim((hmin, hmax))\n",
    "ax.set_ylim((vmin, vmax))\n",
    "ax.invert_yaxis()\n",
    "ax.set_title(\"Transformación con ystretchT\")\n",
    "\n",
    "def update_plot(x, y, k, cx, cy):\n",
    "    pixel.set_data(x = 0, y = 0, dx = x, dy = y)\n",
    "    T = ystretchT(k)\n",
    "    pix = T.dot(np.array([x - cx, y - cy]))\n",
    "    pixelT.set_data(x = 0, y = 0, dx = pix[0] + cx, dy = pix[1] + cy)\n",
    "    center[0].set_data([cx], [cy])\n",
    "    imgplot.set(data=transform(\n",
    "        image,\n",
    "        T,\n",
    "        offset = [cx, cy],\n",
    "    ), clip_on=False,)\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "widget = ipywidgets.interactive(\n",
    "    update_plot,\n",
    "    x = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"x\",\n",
    "        value=x_init,\n",
    "        min=x_min,\n",
    "        max=x_max,\n",
    "        step=x_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    y = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"y\",\n",
    "        value=y_init,\n",
    "        min=y_min,\n",
    "        max=y_max,\n",
    "        step=y_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    k = ipywidgets.FloatSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"k\",\n",
    "        value=k_init,\n",
    "        min=k_min,\n",
    "        max=k_max,\n",
    "        step=k_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    cx = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"cx\",\n",
    "        value=cx_init,\n",
    "        min=cx_min,\n",
    "        max=cx_max,\n",
    "        step=cx_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    cy = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"cy\",\n",
    "        value=cy_init,\n",
    "        min=cy_min,\n",
    "        max=cy_max,\n",
    "        step=cy_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "display(widget)\n",
    "display(fig.canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c804cb55-e0d8-4f4d-a5fe-511ddeb5933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeezeT(factor):\n",
    "    return np.array([[factor, 0],\n",
    "                     [0, 1 / factor]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bf397d-ff39-4a52-bc2f-64139ccffdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(image)\n",
    "show_example(transform(\n",
    "    image,\n",
    "    squeezeT(2),\n",
    "    offset = [14, 14],\n",
    "))\n",
    "show_example(transform(\n",
    "    image,\n",
    "    squeezeT(0.5),\n",
    "    offset = [14, 14],\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999175bf-9e65-4e99-8bad-a7aacbd21476",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "hmin, hmax = -1, 28\n",
    "vmin, vmax = -1, 28\n",
    "\n",
    "x_init, x_min, x_max, x_step = 14, 0, 27, 1\n",
    "y_init, y_min, y_max, y_step = 12, 0, 27, 1\n",
    "k_init, k_min, k_max, k_step = 1, -3, 3, 0.01\n",
    "cx_init, cx_min, cx_max, cx_step = 14, 0, 27, 1\n",
    "cy_init, cy_min, cy_max, cy_step = 14, 0, 27, 1\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot()\n",
    "pixel = ax.arrow(0, 0, x_init, y_init, head_width=0.75, color=\"black\")\n",
    "pixelT = ax.arrow(0, 0, x_init, y_init, head_width=0.75, color=\"blue\")\n",
    "center = ax.plot([cx_init], [cy_init], color=\"blue\", marker = \"o\", linestyle = \"None\")\n",
    "ax.imshow(image, cmap=mpl.cm.autumn, alpha=0.5)\n",
    "imgplot = ax.imshow(image, cmap=mpl.cm.autumn, alpha=0.5)\n",
    "\n",
    "ax.set_xlim((hmin, hmax))\n",
    "ax.set_ylim((vmin, vmax))\n",
    "ax.invert_yaxis()\n",
    "ax.set_title(\"Transformación con squeezeT\")\n",
    "\n",
    "def update_plot(x, y, k, cx, cy):\n",
    "    pixel.set_data(x = 0, y = 0, dx = x, dy = y)\n",
    "    T = squeezeT(k)\n",
    "    pix = T.dot(np.array([x - cx, y - cy]))\n",
    "    pixelT.set_data(x = 0, y = 0, dx = pix[0] + cx, dy = pix[1] + cy)\n",
    "    center[0].set_data([cx], [cy])\n",
    "    imgplot.set(data=transform(\n",
    "        image,\n",
    "        T,\n",
    "        offset = [cx, cy],\n",
    "    ), clip_on=False,)\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "widget = ipywidgets.interactive(\n",
    "    update_plot,\n",
    "    x = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"x\",\n",
    "        value=x_init,\n",
    "        min=x_min,\n",
    "        max=x_max,\n",
    "        step=x_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    y = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"y\",\n",
    "        value=y_init,\n",
    "        min=y_min,\n",
    "        max=y_max,\n",
    "        step=y_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    k = ipywidgets.FloatSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"k\",\n",
    "        value=k_init,\n",
    "        min=k_min,\n",
    "        max=k_max,\n",
    "        step=k_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    cx = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"cx\",\n",
    "        value=cx_init,\n",
    "        min=cx_min,\n",
    "        max=cx_max,\n",
    "        step=cx_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    cy = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"cy\",\n",
    "        value=cy_init,\n",
    "        min=cy_min,\n",
    "        max=cy_max,\n",
    "        step=cy_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "display(widget)\n",
    "display(fig.canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f51fda-4e5a-4523-a035-2edd1f9168fb",
   "metadata": {},
   "source": [
    "## Cizallamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74741119-5616-4bdf-a61e-cf043579d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xshearingT(factor):\n",
    "    return np.array([[1, factor],\n",
    "                     [0, 1]])\n",
    "\n",
    "def yshearingT(factor):\n",
    "    return np.array([[1, 0],\n",
    "                     [factor, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcaf900-f3d1-45d5-9c81-938a55bf87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(image)\n",
    "show_example(transform(\n",
    "    image,\n",
    "    xshearingT(0.5),\n",
    "    offset = [14, 14],\n",
    "))\n",
    "show_example(transform(\n",
    "    image,\n",
    "    yshearingT(0.5),\n",
    "    offset = [14, 14],\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79298253-582e-4a33-b39d-477104331fe3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "hmin, hmax = -1, 28\n",
    "vmin, vmax = -1, 28\n",
    "\n",
    "x_init, x_min, x_max, x_step = 14, 0, 27, 1\n",
    "y_init, y_min, y_max, y_step = 12, 0, 27, 1\n",
    "k_init, k_min, k_max, k_step = 0, -3, 3, 0.01\n",
    "cx_init, cx_min, cx_max, cx_step = 14, 0, 27, 1\n",
    "cy_init, cy_min, cy_max, cy_step = 14, 0, 27, 1\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot()\n",
    "pixel = ax.arrow(0, 0, x_init, y_init, head_width=0.75, color=\"black\")\n",
    "pixelT = ax.arrow(0, 0, x_init, y_init, head_width=0.75, color=\"blue\")\n",
    "center = ax.plot([cx_init], [cy_init], color=\"blue\", marker = \"o\", linestyle = \"None\")\n",
    "ax.imshow(image, cmap=mpl.cm.autumn, alpha=0.5)\n",
    "imgplot = ax.imshow(image, cmap=mpl.cm.autumn, alpha=0.5)\n",
    "\n",
    "ax.set_xlim((hmin, hmax))\n",
    "ax.set_ylim((vmin, vmax))\n",
    "ax.invert_yaxis()\n",
    "ax.set_title(\"Transformación con xshearingT\")\n",
    "\n",
    "def update_plot(x, y, k, cx, cy):\n",
    "    pixel.set_data(x = 0, y = 0, dx = x, dy = y)\n",
    "    T = xshearingT(k)\n",
    "    pix = T.dot(np.array([x - cx, y - cy]))\n",
    "    pixelT.set_data(x = 0, y = 0, dx = pix[0] + cx, dy = pix[1] + cy)\n",
    "    center[0].set_data([cx], [cy])\n",
    "    imgplot.set(data=transform(\n",
    "        image,\n",
    "        T,\n",
    "        offset = [cx, cy],\n",
    "    ), clip_on=False,)\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "widget = ipywidgets.interactive(\n",
    "    update_plot,\n",
    "    x = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"x\",\n",
    "        value=x_init,\n",
    "        min=x_min,\n",
    "        max=x_max,\n",
    "        step=x_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    y = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"y\",\n",
    "        value=y_init,\n",
    "        min=y_min,\n",
    "        max=y_max,\n",
    "        step=y_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    k = ipywidgets.FloatSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"k\",\n",
    "        value=k_init,\n",
    "        min=k_min,\n",
    "        max=k_max,\n",
    "        step=k_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    cx = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"cx\",\n",
    "        value=cx_init,\n",
    "        min=cx_min,\n",
    "        max=cx_max,\n",
    "        step=cx_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    cy = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"cy\",\n",
    "        value=cy_init,\n",
    "        min=cy_min,\n",
    "        max=cy_max,\n",
    "        step=cy_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "display(widget)\n",
    "display(fig.canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a03ea91-23d8-4f5f-8c0b-a1b86cce8f14",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "hmin, hmax = -1, 28\n",
    "vmin, vmax = -1, 28\n",
    "\n",
    "x_init, x_min, x_max, x_step = 14, 0, 27, 1\n",
    "y_init, y_min, y_max, y_step = 12, 0, 27, 1\n",
    "k_init, k_min, k_max, k_step = 0, -3, 3, 0.01\n",
    "cx_init, cx_min, cx_max, cx_step = 14, 0, 27, 1\n",
    "cy_init, cy_min, cy_max, cy_step = 14, 0, 27, 1\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot()\n",
    "pixel = ax.arrow(0, 0, x_init, y_init, head_width=0.75, color=\"black\")\n",
    "pixelT = ax.arrow(0, 0, x_init, y_init, head_width=0.75, color=\"blue\")\n",
    "center = ax.plot([cx_init], [cy_init], color=\"blue\", marker = \"o\", linestyle = \"None\")\n",
    "ax.imshow(image, cmap=mpl.cm.autumn, alpha=0.5)\n",
    "imgplot = ax.imshow(image, cmap=mpl.cm.autumn, alpha=0.5)\n",
    "\n",
    "ax.set_xlim((hmin, hmax))\n",
    "ax.set_ylim((vmin, vmax))\n",
    "ax.invert_yaxis()\n",
    "ax.set_title(\"Transformación con yshearingT\")\n",
    "\n",
    "def update_plot(x, y, k, cx, cy):\n",
    "    pixel.set_data(x = 0, y = 0, dx = x, dy = y)\n",
    "    T = yshearingT(k)\n",
    "    pix = T.dot(np.array([x - cx, y - cy]))\n",
    "    pixelT.set_data(x = 0, y = 0, dx = pix[0] + cx, dy = pix[1] + cy)\n",
    "    center[0].set_data([cx], [cy])\n",
    "    imgplot.set(data=transform(\n",
    "        image,\n",
    "        T,\n",
    "        offset = [cx, cy],\n",
    "    ), clip_on=False,)\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "widget = ipywidgets.interactive(\n",
    "    update_plot,\n",
    "    x = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"x\",\n",
    "        value=x_init,\n",
    "        min=x_min,\n",
    "        max=x_max,\n",
    "        step=x_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    y = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"y\",\n",
    "        value=y_init,\n",
    "        min=y_min,\n",
    "        max=y_max,\n",
    "        step=y_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    k = ipywidgets.FloatSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"k\",\n",
    "        value=k_init,\n",
    "        min=k_min,\n",
    "        max=k_max,\n",
    "        step=k_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    cx = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"cx\",\n",
    "        value=cx_init,\n",
    "        min=cx_min,\n",
    "        max=cx_max,\n",
    "        step=cx_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    "    cy = ipywidgets.IntSlider(\n",
    "        orientation=\"horizontal\",\n",
    "        description=\"cy\",\n",
    "        value=cy_init,\n",
    "        min=cy_min,\n",
    "        max=cy_max,\n",
    "        step=cy_step,\n",
    "        layout=ipywidgets.Layout(width=\"90%\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "display(widget)\n",
    "display(fig.canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60d3657-6c8c-4575-8393-8ce68ae6f3b6",
   "metadata": {},
   "source": [
    "Las imagenes usualmente se escriben con un ladeado sobre el eje $x$. La transformación de cizallamiento, en particular `xshearingT` nos puede ayudar a rectificar lo ladeado de las imágenes.  La transformación es:\n",
    "\n",
    "$$\\mathtt{xshearingT}(k) = \\begin{bmatrix}\n",
    "1 & k \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Por lo que para un pixel en $(x, y)$, esta transformación lo asocia a la posición $(x + ky, y)$. Por lo que un desplazamiento en $x$ será indistinto para el efecto buscado, en cambio, el desplazamiento en $y$ será determinante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd6d306-72fd-41f4-a682-590da33effcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(transform(\n",
    "    image,\n",
    "    xshearingT(0.5),\n",
    "    offset = [0, 0],\n",
    "))\n",
    "show_example(transform(\n",
    "    image,\n",
    "    xshearingT(0.5),\n",
    "    offset = [0, 4.5],\n",
    "))\n",
    "show_example(transform(\n",
    "    image,\n",
    "    xshearingT(0.5),\n",
    "    offset = [0, 7],\n",
    "))\n",
    "show_example(transform(\n",
    "    image,\n",
    "    xshearingT(0.5),\n",
    "    offset = [0, 11.5],\n",
    "))\n",
    "show_example(transform(\n",
    "    image,\n",
    "    xshearingT(0.5),\n",
    "    offset = [0, 14],\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f4d237-88af-4c6d-bdff-0e10af821b15",
   "metadata": {},
   "source": [
    "A partir de una imágen, ¿Cómo podemos determinar el factor de cizallamiento en $x$? ¿Cómo podemos determinar el desplazamiento en $y$ adecuado?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7153fd2-d6ae-4c8d-a23a-37307cab2ff8",
   "metadata": {},
   "source": [
    "Para el desplazamiento, podemos calcular en qué punto se encuentra el valor central de la imagen sobre el eje $x$. Esto nos permitiría obtener el punto de balance sobre este eje para realizar la transformación allí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cdf998-7eaa-406d-a09c-4e8fbde10219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizar un meshgrid puede resultar más eficiente que ciclos anidados!\n",
    "idx_x, idx_y = np.mgrid[:28,:28]\n",
    "total = np.sum(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc64a6-cebe-4beb-9e04-453c8ea3cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_x = np.sum(idx_x * image) / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182991c4-e5b3-4fce-b170-7cefc7798680",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d92e449-ae80-41a6-9dae-595ef9f46c24",
   "metadata": {},
   "source": [
    "De manera análoga podemos identificar el valor central sobre $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423323e-be9c-4bb5-a0af-26021f27ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_y = np.sum(idx_y * image) / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c7ba6b-b4a2-4008-a693-36449698240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f6261-b716-418a-b6fc-9ddd2cb6bfc0",
   "metadata": {},
   "source": [
    "Para determinar el factor de cizallamiento, podemos utilizar la covarianza para determinar la dependencia lineal entre los valores en $x$ y $y$. La normalizamos por la varianza sobre el eje de las $x$, contemplando la variación en la escala del eje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7558c9-fa56-4987-8570-9a10fe191d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_x = np.sum((idx_x - mu_x)**2 * image) / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e616367-2dae-4eee-b353-502ae5381c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_xy = np.sum((idx_y - mu_y) * (idx_x - mu_x) * image) / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04a5ab-22ef-47c8-88b4-9edb0eea5e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "-cov_xy / var_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3817ad58-9c93-4c44-b657-246e3d753e37",
   "metadata": {},
   "source": [
    "Creamos una abstracción sobre estos cálculos para rectificar lo ladeado de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03adb755-e47e-4dfa-b18a-50db7b1e327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unskew_params(image):\n",
    "    h, w = image.shape\n",
    "    idx_x, idx_y = np.mgrid[:h, :w]\n",
    "    total = np.sum(image)\n",
    "    mu_x = np.sum(idx_x * image) / total\n",
    "    mu_y = np.sum(idx_y * image) / total\n",
    "    var_x = np.sum((idx_x - mu_x)**2 * image) / total\n",
    "    cov_xy = np.sum((idx_y - mu_y) * (idx_x - mu_x) * image) / total\n",
    "    return -cov_xy / var_x, [mu_x, mu_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cce373-77a2-4414-b60c-1ddcddd15056",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mgrid[:5,:5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b885f3a-e849-46f0-901a-540b1d7d4485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_drawing():\n",
    "    img = plt.imread(\"drawing.png\")\n",
    "    img = (255*(1-img)).astype('uint8')\n",
    "    k, [cx, cy] = unskew_params(img)\n",
    "    plt.close()\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "    ax.imshow(img, cmap=mpl.cm.magma)\n",
    "    ax.plot([0, 27], [cy, cy], c=\"green\", lw=3.0)\n",
    "    ax.arrow(13, 0, -k*7, 0, head_width=0.75, lw=3.0, color=\"green\")\n",
    "    ax.arrow(13, 27, k*7, 0, head_width=0.75, lw=3.0, color=\"green\")\n",
    "    ax.set_xlim((0, 27))\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dbaca4-533e-417b-87a6-099a22638d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_drawing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b2287-cf9d-4536-aa50-c34a9f8dda40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unskew_image(image):\n",
    "    k, offset = unskew_params(image)\n",
    "    return transform(\n",
    "        image,\n",
    "        xshearingT(k),\n",
    "        offset = offset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2886b165-8c6a-4b61-bc4f-fd03f63db2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.random.randint(len(images))\n",
    "show_example(images[n], labels[n])\n",
    "show_example(unskew_image(images[n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75a7a45-b280-46ed-8cee-bc28dc74f427",
   "metadata": {},
   "source": [
    "Transformemos las imagenes para rectificar lo ladeadas que están. Esto puede resultar muy tardado, por lo que aprovecharemos el multiprocesamiento de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c8bde-8c2d-4218-8667-db89197bc24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4fb947-2c0f-4d40-9e2b-92242a7eda1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unskew_images(images):\n",
    "    with Pool() as pool:\n",
    "        return pool.map(unskew_image, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a10c2-27a5-44b5-b3f5-0a7054482c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "imagesT = unskew_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298fe918-83ec-4a34-8d15-328c0d570104",
   "metadata": {},
   "source": [
    "Y probemos qué tal funcionan nuestras rústicas maquinarias lineales de predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8852ddf1-405d-4ffb-b006-ca7e6fe5e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5bee2a-b7d3-4354-9925-7b3eaf93574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_weights():\n",
    "    return np.zeros(image_rows * image_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3545501d-0310-42ae-b455-951e0dc2e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, x):\n",
    "    return np.sign(w.dot(features(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a9db55-b2e8-4d40-9432-9a9f9b8aab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin(x, y, w):\n",
    "    return predict(w, x)*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b62735-491c-4dd9-bf0b-248066924172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_hinge(x, y, w):\n",
    "    return max(1 - margin(x, y, w), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81437d-931c-4168-ba78-bf06b35bb462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_loss_hinge(x, y, w):\n",
    "    return -features(x)*y if margin(x, y, w) < 1 else np.zeros_like(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988f6fff-8cb8-461b-8cb0-1bf014c3b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loss(Dtrain, loss, w):\n",
    "    examples = len(Dtrain)\n",
    "    total = sum(loss(x, y, w) for x, y in Dtrain)\n",
    "    return total / examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd90daa-f9e7-436b-a54f-13226b6aff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_train_loss(Dtrain, grad_loss, w):\n",
    "    examples = len(Dtrain)\n",
    "    total = sum(grad_loss(x, y, w) for x, y in Dtrain)\n",
    "    return total / examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eb6356-52af-4608-9262-c27173ec6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eta_decreasing(init_eta):\n",
    "    def decreaser(n):\n",
    "        return init_eta / np.sqrt(n)\n",
    "    return decreaser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f0d790-576c-49d1-af97-5878012d7231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(data, loss, grad_loss, init_weights, eta, epochs):\n",
    "    w_hist = []\n",
    "    tl_hist = []\n",
    "    w = init_weights()\n",
    "    for t in range(1, epochs + 1):\n",
    "        tl = train_loss(data, loss, w)\n",
    "        gtl = grad_train_loss(data, grad_loss, w)\n",
    "        w_hist.append(w)\n",
    "        tl_hist.append(tl)\n",
    "        w = w - eta * gtl\n",
    "    return w, (w_hist, tl_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701db222-ee14-4651-881f-cf4ac99eb823",
   "metadata": {},
   "outputs": [],
   "source": [
    "DtrainRaw = [\n",
    "    (images[i].reshape(image_rows * image_cols),\n",
    "     +1 if labels[i] == 0 else -1)\n",
    "    for i in range(image_total)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425544c7-cf6b-41d0-a192-a038a25d349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DtrainT = [\n",
    "    (imagesT[i].reshape(image_rows * image_cols),\n",
    "     +1 if labels[i] == 0 else -1)\n",
    "    for i in range(image_total)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe50ca8-027a-4cc6-a5e8-cf628def50e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gd1_w, (gd1_ws, gd1_tls) = GD(\n",
    "            data = DtrainRaw,\n",
    "            loss = loss_hinge,\n",
    "       grad_loss = grad_loss_hinge,\n",
    "    init_weights = zero_weights,\n",
    "             eta = 0.1,\n",
    "          epochs = 20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d878e2-c716-4211-be1c-e67e709ebdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gd2_w, (gd2_ws, gd2_tls) = GD(\n",
    "            data = DtrainT,\n",
    "            loss = loss_hinge,\n",
    "       grad_loss = grad_loss_hinge,\n",
    "    init_weights = zero_weights,\n",
    "             eta = 0.1,\n",
    "          epochs = 20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b42dc1-ca1c-4fb5-9451-253a0a83b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "epochs = list(range(1, len(gd1_tls) + 1))\n",
    "ax.plot(epochs, gd1_tls, label = \"GD Raw\")\n",
    "ax.plot(epochs, gd2_tls, label = \"GD Deskew\")\n",
    "ax.legend()\n",
    "ax.set_title(\"Learning with linear classifier and hinge loss\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"TrainLoss\")\n",
    "ax.set_xlim((epochs[0], epochs[-1]))\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "display(fig.canvas);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80db06b5-f16b-40c2-b03a-66813320e87b",
   "metadata": {},
   "source": [
    "<img src=\"https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExMHRiZ21sOWdibDY5cmdidmtwNzRqNmo4NXc4MzRyaHNuZ28zbnhqMyZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/tkApIfibjeWt1ufWwj/giphy.gif\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e734f630-74fe-4977-ae1a-aa1c4517c613",
   "metadata": {},
   "source": [
    "## ¿Qué otros tipos de transformaciones podemos utilizar?\n",
    "\n",
    "Un kernel o matriz de convolución es una pequeña matriz (como las transformaciones lineales que ya vimos) que nos permite aplicar algunos efectos como blur, sharpening, detección de bordes ,etc.\n",
    "\n",
    "Estas matrices se aplican diferente a las que ya discutimos. Obtenemos los nuevos valores de los pixeles iterando la matriz sobre la imagen original, la matriz puede tomar valores de una vecindad del pixel destino, permitiendo incorporar información local al pixel en la transformación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43146683-b18d-48c9-a404-f667c9db45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(image, T):\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]\n",
    "    th, tw = T.shape\n",
    "    assert th == tw\n",
    "    assert th % 2 == 1\n",
    "    half = th // 2\n",
    "    imageT = np.zeros_like(image)\n",
    "    for y in range(half, h - half):\n",
    "        for x in range(half, w - half):\n",
    "            imageT[y,x] = (T * image[y - half : y + half + 1, x - half : x + half + 1]).sum()\n",
    "    return imageT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd5eb0-5bbd-4c51-854a-2e27a808edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identityC():\n",
    "    return np.array([[0, 0, 0],\n",
    "                     [0, 1, 0],\n",
    "                     [0, 0, 0]])\n",
    "\n",
    "def edges1C():\n",
    "    return np.array([[0, -1, 0],\n",
    "                     [-1, 4, -1],\n",
    "                     [0, -1, 0]])\n",
    "\n",
    "def edges2C():\n",
    "    return np.array([[-1, -1, -1],\n",
    "                     [-1, 8, -1],\n",
    "                     [-1, -1, -1]])\n",
    "\n",
    "def sharpenC():\n",
    "    return np.array([[0, -1, 0],\n",
    "                     [-1, 5, -1],\n",
    "                     [0, -1, 0]])\n",
    "\n",
    "def boxblurC():\n",
    "    return 1/9 * np.ones((3,3))\n",
    "\n",
    "def gaussianblur1C():\n",
    "    return 1/16 * np.array([[1, 2, 1],\n",
    "                            [2, 4, 2],\n",
    "                            [1, 2, 1]])\n",
    "\n",
    "def gaussianblur2C():\n",
    "    return 1/256 * np.array([[1, 4, 6, 4, 1],\n",
    "                             [4, 16, 24, 16, 4],\n",
    "                             [6, 24, 36, 24, 6],\n",
    "                             [4, 16, 24, 16, 4],\n",
    "                             [1, 4, 6, 4, 1]])\n",
    "\n",
    "def unsharpmaskingC():\n",
    "    return -1/256 * np.array([[1, 4, 6, 4, 1],\n",
    "                              [4, 16, 24, 16, 4],\n",
    "                              [6, 24, -476, 24, 6],\n",
    "                              [4, 16, 24, 16, 4],\n",
    "                              [1, 4, 6, 4, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fafd340-cee7-4590-b3f7-a2852f305de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.random.randint(len(images))\n",
    "show_example(images[n], labels[n])\n",
    "show_example(convolve(images[n], edges1C()))\n",
    "show_example(convolve(images[n], edges2C()))\n",
    "show_example(convolve(images[n], sharpenC()))\n",
    "show_example(convolve(images[n], boxblurC()))\n",
    "show_example(convolve(images[n], gaussianblur1C()))\n",
    "show_example(convolve(images[n], gaussianblur2C()))\n",
    "show_example(convolve(images[n], unsharpmaskingC()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095bdc85-95d1-4d99-ae62-43e88a9d367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_homie():\n",
    "    base_path = \"../20241/fotos/\"\n",
    "    try:\n",
    "        photos = os.listdir(base_path)\n",
    "        photo = np.random.choice(photos)\n",
    "        return plt.imread(base_path + photo).mean(axis=2)\n",
    "    except:\n",
    "        return random_homie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bced03f-1aa8-454a-9120-3851a8112ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_homie(homie):\n",
    "    plt.close()\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "    ax.imshow(homie, cmap=mpl.cm.gray)\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb24a932-4bf7-455a-9936-e3c72100499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "homie = random_homie()\n",
    "show_homie(homie)\n",
    "show_homie(convolve(homie, edges1C()))\n",
    "show_homie(convolve(homie, edges2C()))\n",
    "show_homie(convolve(homie, sharpenC()))\n",
    "show_homie(convolve(homie, boxblurC()))\n",
    "show_homie(convolve(homie, gaussianblur1C()))\n",
    "show_homie(convolve(homie, gaussianblur2C()))\n",
    "show_homie(convolve(homie, unsharpmaskingC()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0afd6-733e-435a-bddf-265217acd3e6",
   "metadata": {},
   "source": [
    "La convolución de `unsharpmaskingC` se mira chistosa, usémosla junto con `deskew` para entrenar un clasificador lineal y comparar la pérdida de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a1941c-1163-4c3e-8ea4-8ec11f558c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsharp_image(image):\n",
    "    return convolve(image, unsharpmaskingC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a1afcb-a996-43b6-bbb2-85a4ee7ef38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsharp_images(images):\n",
    "    with Pool() as pool:\n",
    "        return pool.map(unsharp_image, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6317de38-915d-41fc-8029-4f3f04b079c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "imagesTC = unsharp_images(imagesT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d1ae02-0ef3-4c1d-a8ff-56f43d09914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DtrainTC = [\n",
    "    (imagesTC[i].reshape(image_rows * image_cols),\n",
    "     +1 if labels[i] == 0 else -1)\n",
    "    for i in range(image_total)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02537c05-7ac3-4fcf-8f04-a330064cfe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gd3_w, (gd3_ws, gd3_tls) = GD(\n",
    "            data = DtrainTC,\n",
    "            loss = loss_hinge,\n",
    "       grad_loss = grad_loss_hinge,\n",
    "    init_weights = zero_weights,\n",
    "             eta = 0.1,\n",
    "          epochs = 20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeafe38-db3e-4eb9-94bb-dfd8e89e8fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "epochs = list(range(1, len(gd1_tls) + 1))\n",
    "ax.plot(epochs, gd1_tls, label = \"GD Raw\")\n",
    "ax.plot(epochs, gd2_tls, label = \"GD Deskew\")\n",
    "ax.plot(epochs, gd3_tls, label = \"GD Deskew Unsharp\")\n",
    "ax.legend()\n",
    "ax.set_title(\"Learning with linear classifier and hinge loss\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"TrainLoss\")\n",
    "ax.set_xlim((epochs[0], epochs[-1]))\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "display(fig.canvas);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ab27e-cb4b-418c-8edd-7dd49db11829",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd2_w, (gd2_ws, gd2_tls) = GD(\n",
    "            data = DtrainT,\n",
    "            loss = loss_hinge,\n",
    "       grad_loss = grad_loss_hinge,\n",
    "    init_weights = zero_weights,\n",
    "             eta = 0.1,\n",
    "          epochs = 100,\n",
    ")\n",
    "gd3_w, (gd3_ws, gd3_tls) = GD(\n",
    "            data = DtrainTC,\n",
    "            loss = loss_hinge,\n",
    "       grad_loss = grad_loss_hinge,\n",
    "    init_weights = zero_weights,\n",
    "             eta = 0.1,\n",
    "          epochs = 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be661bb0-5d80-46b0-a417-1287a4210ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TrainLoss con Deskew + Unsharpen:\", gd3_tls[-1])\n",
    "print(\"TrainLoss con Deskew:\", gd2_tls[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad8acb1-ecc0-44f2-be9a-861451921861",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd3_tls[-1] < gd2_tls[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa944c8-3bad-4e9c-b80a-7b7f575841e0",
   "metadata": {},
   "source": [
    "<img src=\"https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExeDI1MnY1eWIwM2V3NGphYXNjMWFkOWlwMWxzMms2MzRqNWo4N2tmciZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/pynZagVcYxVUk/giphy.gif\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1038cdca-c129-4aec-a768-1130cee846b7",
   "metadata": {},
   "source": [
    "# Dudas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b2212d-4bff-4a4d-b175-d4ac97d1e770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb5ce0e-7919-4957-8c8c-85c047dd7977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05783f56-3406-47be-800d-7170d7a102d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128436f0-27b5-4b98-983c-9a43c43e5f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc5c4a1-c242-4774-8fb1-f541bf632562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b8a70d-ba8e-47af-b7ba-718541339cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8226ce66-b690-47b0-8866-f394d2e40ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fa1684-b06b-40de-9df5-f74b11da0c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4219575f-a8b3-4243-a7ca-74d102b0b0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a71c3-a7bf-454c-84d0-1ad9bb066649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1e3af5-7cc5-45d8-874c-7a2c03a8f2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b51abd-4e41-44d5-898a-66fe7cb06b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b7fa54-e5fb-4a3d-8e0f-c5b32b78f22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d1db31-84cf-434a-8132-534c039a05f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e72c3-ba51-48c4-9b50-4158f2fae5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b2fb0-89ee-4365-afb6-4cf30bff5cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce9269-87e2-43dc-ba7f-35a923569f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f76111b-cc51-4ce2-8e4b-168e0d27e564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab95c9-b6a3-454b-b9f0-1c1d64c21a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a9326-6229-4f4d-9efc-6e4cdbbe340a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c2927c-a52d-4a3b-b74e-aa5aca7b5f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f70dc-336b-4877-bb46-3ac5d6615fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a598eb-6467-41f0-a933-b47e726f59ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ceb97c-0570-4eae-b7f7-c04512143455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0833421b-327a-40e6-80c1-8fda976ceb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a80fb00-7f9e-4a5d-9aca-5f2143277303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53dfad5-70e1-4429-b770-0f922455f8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db4dfe8-d0f5-48fc-b47a-9badd992fdb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25008fb3-f893-4c1c-9c1f-530897880af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13169d05-ad10-4db4-9dfe-f095159253ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2bafe9-e89c-4148-88e7-4b14792f09a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5cd30f-e162-44f5-8069-c547ccbb4bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f1ce20-3b89-4665-8d85-fc34bebfe615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3d5650-a97c-4bb2-94c1-22a40f6f1a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e2f25-3da6-4497-b256-76126270ab62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79a7ac-8e54-4a10-acc9-8ff6a9f841ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e96549-da3c-4003-a68d-bdfce2c23e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79d6100-967e-4fc0-b4da-56e7b60a5959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7752703f-de52-447d-8296-07786f5a92a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270a279-6a90-436e-a61a-5db7c5aabf99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b07e28-1337-429d-8875-b88c8a28d74d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c32b8-aaca-4078-90b1-a4a0d2c20623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efa0b7a-0ed7-4517-bfb8-6b0f365c653b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba33e5-fcf0-428f-8b9b-f2eb73ddc094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb0af3-598e-40ed-8e26-dc9918085458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4257be2-d234-4c51-9dfe-4d7a262ed597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52794cad-856a-403e-a5c4-0422d2193389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19533859-32dd-420b-8b5f-38038d923458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ce645-680c-4118-b92d-198c3bca92de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ced4ef-a6ef-4da8-b19d-e5b93f8880e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e0c41-9f9d-4874-8d94-9b178884189b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c374fec7-0f28-4d76-9258-0d1c472eb616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8908bad7-c0f5-4cba-a30c-5fd2aea3f185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f319b6-c9f7-403b-a603-a24f779f0037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4296914a-0ffd-4175-9e4c-0cf332754a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd34be-06b8-4308-a915-91a304d8fc46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa365173-d85a-4194-a646-f7532fb5e7de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e80ad-3173-4b3b-94ac-33ee3891737b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87e00925-acc5-431c-9967-7112ebb63e60",
   "metadata": {},
   "source": [
    "Consideremos el predictor para el dígito $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc56402-2bfa-4b59-b765-60845bddb9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(Dtrain):\n",
    "    return GD(\n",
    "        data = Dtrain,\n",
    "        loss = loss_hinge,\n",
    "   grad_loss = grad_loss_hinge,\n",
    "init_weights = zero_weights,\n",
    "         eta = 0.1,\n",
    "      epochs = 100,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9cf8b9-7185-4d44-a407-2f8ac7e20b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0, (ws0, tls0) = learn(DtrainRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a09392-3a53-4886-97b4-bf22d8d4e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss(DtrainRaw, loss_hinge, w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad55230c-c874-4389-a53a-7c0f22b052ff",
   "metadata": {},
   "source": [
    "Este es un clasificador para el cero, permite predecir si una imagen contiene cero o no contiene cero.\n",
    "\n",
    "Hemos logrado una pérdida de entrenamiento de $0.19743333333333332$, pero esta baja pérdida es engañosa.\n",
    "¿Qué nos dice?\n",
    "¿Esperamos predecir correctamente imagenes con el $0$ un $80\\%$ de las veces?\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExcG1pOTdjdGxrbWYwYnYzM3lwd3p5ZHRlbWczZGI1dWhzMWo3NGI5eSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/TnDWOEP7dI9LG/giphy.gif\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5789ef-27aa-4fbf-825c-a09fc9c12113",
   "metadata": {},
   "source": [
    "¿Cuántos dígitos cero predecimos correctamente como cero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac4dd1-5ce0-469c-87e0-370e6b2b85ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_prediction0(image, label):\n",
    "    predicted = np.sign(w0.dot(features(image.reshape(image_rows * image_cols))))\n",
    "    return label == 0 and predicted > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252cf2d9-efc7-4782-a631-141580fe330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(correct_prediction0(image, label) for image, label in zip(images, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3f4a03-6aa8-4a78-8556-97a393ab8315",
   "metadata": {},
   "source": [
    "Caracoles, ninguna de las imágenes que tienen escrito un cero son predecidas correctamente...\n",
    "¿Será que nos falta entrenar con más épocas?\n",
    "¿Será que debemos replantear el problema de manera distinta?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30da72cb-f072-4132-a542-be783b7bc747",
   "metadata": {},
   "source": [
    "<img src=\"https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExbHJsYzFhcmJqZG52dHA4cGk1bDRlM2JzMGQwMmdkczR3amJyajlwbiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3o7TKSxdQJIoiRXHl6/giphy.gif\"></img>\n",
    "\n",
    "Implementa un clasificador multi-clase para los dígitos 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. Te invito a incorporar características adicionales, utilizar plantillas de características, incorporar distintas transformaciones lineales y convoluciones.\n",
    "\n",
    "¿Qué tanto puedes bajar la pérdida de entrenamiento?\n",
    "¿Puedes lograr predecir dígitos?\n",
    "\n",
    "Fortuna y gloria le esperan a quien se aventure en esta exploración y presente un reporte de sus hallazgos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
